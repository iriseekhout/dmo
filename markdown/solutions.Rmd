---
title: "Solutions - Missing data workshop"
author: "dr. Iris Eekhout"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	comment = ">"
)
```

# Missing value analyses

## Solution 1: amount of missing values

```{R}
# load library mice to load boys data
library(mice)
```

**a. How many variables have missing data?**

All variables, except for age, have missing values, so in total 8 out of 9 variables have missing data.

```{r}
# summary to see which variables have missing data
summary(boys)
```

**b. How many rows in the data contain missing values?** 

In total 525 rows in the data have missing values, this is ~70%. 

```{r}
nic(boys)
nic(boys)/nrow(boys)
```

**c. How many overall matrix entries are missing? And how many observed?**

1622 matrix entries are missing and 5110 are observed; ~25% of the matrix entries are missing.

```{r}
sum(is.na(boys))
sum(!is.na(boys))

1622/(1622+5110)
```


## Solution 2: missing data patterns

**a. How many different missing data patterns occur in the data?**

14 patterns

```{r}
nrow(mice::md.pattern(boys, plot= T))

```


**b. What is the most frequently occurring pattern in the data?**

The pattern with "gen", "phb" and "tv" missing, occurs 437 times.

```{r}
mice::md.pattern(boys, plot= T)

```

**c. Looking at patterns that occur more than incidental (once or twice), which variables happen to be missing together often?**

Variables that are most often missing at the same time are "gen", "phb", and "tv". The patterns that occur more than once involve mostly all of these variables (pattern with "hc" and "gen", "pbh", "tv" 43 times and the pattern with "hgt", "bmi" and  "gen", "phb", "tv" 16 times, pattern "reg" and "gen", "phb", "tv", 3 times, pattern with "tv" mising 19 times).


**d. Inspect the missing data pairs. With what other variable(s) is height observed together with in more than half of the cases?**

The answer can be found looking at the first matrix `rr`. In the row of "hgt", the column values that are higher than 374 indicate variables that are observed with hgt more than half of the time: "age", "wgt", "bmi", "hc", and "reg".

```{r}
mice::md.pairs(boys)
```


## Solution 3: understanding missing data mechanisms

**a. What is the mean and standard deviation of knee pain score? And the association between BMI and knee pain (coefficient, standard error and p-value)?**

Mean= 14.81, sd=3.21; The association is significant with coefficient=0.35; se=0.14.

**b. What are the mean and standard deviation of the knee pain score? What is association between BMI and knee pain?**

Mean= 14.70, sd=3.24; The association is not significant (coefficient=0.33; se=0.18).

**c. How do these results compare to the complete data results?**

The mean and standard deviation have not changed much, however the power for the association was decreased which caused the association between BMI and knee pain to not be significant anymore. 

**d. What happens to the association between BMI and knee pain? Explain differences with the previous answer (sample size 100).**

At 0% missing: coefficient=0.57 and se=0.08 (significant); at 30% missing: coefficient=0.53 and se=0.10 (significant). The association does not change (much) and remains significant. The difference with answer c is explained by the change in sample size. Larger sample size, makes the analysis more robust against (MCAR) missing data.

**e. What is the association between BMI and knee pain? How does this compare to the association when the data were MCAR?**

There is a significant association with a coefficient of 0.49, se=0.11; the association is now less strong; the coefficient is lower (biased) (was 0.57 for 0% missing) and the standard error has increased slightly (was 0.08 for 0% missing).

**f. When there are 30% MAR missing data at sample size 250, at what BMI values do missing data on knee pain occur (inspect the scatterplot and the boxplots).**

More missing values at higher BMI values.

**g. Comparing the histograms, what knee pain values are mostly missing?**

In the MNAR situation, more missings are present in the higher values of knee pain. 

**h. What happens with thee association between BMI and knee pain?**

* MCAR: coefficient= 0.46; se=0.10
* MAR: coefficient=0.37; se=0.11
* MNAR: coefficient=0.27; se=0.11 
* 0% missing: coefficient=0.54; se=0.07.

The association becomes less strong when you change from MCAR to MAR to MNAR, so coefficients get more biased. Also for MCAR the missings are nicely distributed over the BMI values. In the MAR mechanism there are more missings at higher values of BMI but also lower Knee Pain scores are missing. In the MNAR mechanism, mostly higher values of Knee Pain scores are missing.

**i What happens with the mean and standard deviation of the knee pain score?**

* MCAR: mean=14.79; sd=2.98 
* MAR: mean=14.01; sd=2.85
* MNAR: mean= 13.34; sd=2.69
* 0%missing: mean=14.77; sd=3.11

Both mean and standard deviation decrease when changing from MCAR to MAR to MNAR.


## Solution 4: evaluating the missing data mechanism

**a. Evaluate the missing data mechanism for the airquality data with univariate tests. What are your conclusions?**

Evaluation using T-tests for continuous variables and the Chi-square for categorical variables.


First create the missing data indicators for each variable with missing data.
```{r}
library(dplyr)
summary(airquality)
airqualitym <- airquality %>%
  #create missing data indicators
  mutate(ROzone = is.na(Ozone),
         RSolar.R = is.na(Solar.R))

```

Do a T-test for each missing data indicator with the continuous variables and a chi square test for the categorical variables. We investigate Month as categorical, but it can also be used as continuous.

* Missing data in Ozone are related to Month, the probability for missing Ozone data is higher earlier in the year.

* The Chi-square test Solar.R and Month seems significant, but also throws a warning. So we cannot really be sure about the results. Probably also because there are only few missings in Solar.R. Tests for the other variables do not show a relation with the probability of missing data in Solar.R

Based on the univariate analyses we may conclude that the missing data are not Missing Completely at Random (not-MCAR). There are other measured variable related to the probability of missing data. 



```{r}
# Univariate tests for Ozone
t.test(Solar.R ~ ROzone, data = airqualitym)
t.test(Wind ~ ROzone, data = airqualitym)
t.test(Temp ~ ROzone, data = airqualitym)
t.test(Month ~ ROzone, data = airqualitym)
t.test(Day ~ ROzone, data = airqualitym)
chisq.test(airqualitym$ROzone, airqualitym$Month)


```


```{r}
# Univariate tests for Solar.R
t.test(Ozone ~ RSolar.R, data = airqualitym)
t.test(Wind ~ RSolar.R, data = airqualitym)
t.test(Temp ~ RSolar.R, data = airqualitym)
t.test(Month ~ RSolar.R, data = airqualitym)
t.test(Day ~ RSolar.R, data = airqualitym)
chisq.test(airqualitym$RSolar.R, airqualitym$Month)


```




**b. Evaluate the missing data mechanism for the airquality data with a multivariate test. What are your conclusions?**

First, investigate which variables have missing data in the `airquality` data: Ozone and Solar.R 

```{r}
summary(airquality)
mice::md.pattern(airquality)
```

Create missing data indicators for these two variables. Additional, we can also make one missing indicator for any missing values. Note that this is only useful if we have at least some variables that have no missing data. 

```{r}
airqualitym <- airquality %>%
  mutate(ROzone = is.na(Ozone),
         RSolar.R = is.na(Solar.R),
         Rind = is.na(Ozone) | is.na(Solar.R))

```

Do a logistic regression analysis for each of the missing data indicators. Both Temp and Month seem to be related to the missing values in Ozone. There are no measured variables related to the missing values in Solar.R. Based on these results we can conclude that the missing values in the airquality dataset are not-MCAR.

```{R}
glm(ROzone ~ Solar.R + Wind + Temp + Month + Day, data = airqualitym, family = "binomial") %>% summary
glm(RSolar.R ~ Ozone + Wind + Temp + Month + Day, data = airqualitym, family = "binomial") %>% summary

# analysis for the indicator of overall missing data
glm(Rind ~ Wind + Temp + Month + Day, data = airqualitym, family = "binomial") %>% summary

```

# Multiple imputation

## Solution 5: multiple imputation in `mice`

**a. How many imputed datasets are generated?**

The output returned from the mice functions states: "Number of multiple imputations: 5". 

```{R}
imp <- mice(nhanes2)
imp
```

**b. How many sets of results are generated** 

The `with` function can be used to automatically analyze all imputed datasets. The analysis results are stored as `fit`. There are 5 sets of results generated.

```{R}
fit <- with(imp, lm(bmi ~ age + hyp + chl))
fit
```

**c. What are the most relevant predictors for bmi?**

The most relevant predictors are age and cholesterol. Older respondents have a lower bmi, whereas cholesterol is positively related (higher cholesteral means a higher bmi). 

```{R}
combi <- pool(fit)
summary(combi)

``` 


## Solution 6: multiple imputation model and convergence

**a. Adjust the predictor matrix so that the variables that have more than 50% missing values are excluded as predictors for the imputation.** 

First create the predictor matrix for the `boys` dataset with the `make.predictorMatrix()` function in `mice`. 

```{r}
pred <- make.predictorMatrix(boys)
```

Inspect the boys dataset, and find out what variables have more than 50% missing values. These are "gen", "phb", and "tv". 

```{r}
colMeans(is.na(boys))

```

Now, exclude variables "gen", "phb", and "tv" as predictors from this matrix. Note that predictors are in the columns.

```{r}
pred[,c("gen", "phb", "tv")] <- 0
pred
```

Perform multiple imputation on the `boys` data with the predictor matrix designed at assignment 6a with 10 imputations and 10 iterations.

```{r}
imp <- mice(boys, m = 10, maxit = 10, predictorMatrix = pred)
```

**b. What methods are used for the imputation of each variable and explain why these are used.**

* For "hgt", "wgt", "bmi", "hc" and "tv" the "pmm" (predictive mean matching) method is used. This is the default for continuous variables and the variables indicated are all continuous. 
* For "gen" and "phb" the "polr" method is used, which is the default for ordinal variables. The imputation function is a proportional odds model.
* For "reg" the "polyreg" method is used. This method is de default for unordered nominal variables and is the polytomous logistic regression. 


```{r}
imp$method
``` 

**c. Inspect the iteration plots. What are your observations?**

```{r}
plot(imp)
``` 


The iteration plots for the variables "hc", "gen", "phb", "tv", and "reg" all show crossing interacting lines that are more or less centered around. For the variables "hgt", "wgt" and "bmi" the lines to not cross as much and some lines are below the mean for all iterations, whereas other lines are above the mean for all iterations. So the iteration plots for "hgt", "wgt" and "bmi" do not show a very good convergence. 



**d. Adjust the predictor matrix such that hgt and wgt are not imputed by bmi, or vice versa, and that hgt and wgt are not used as predictors together with bmi. Why do you think that these changes are needed?**

Option 1:

First, we remove "hgt" and "wgt" as predictors for the imputaiton of "bmi". Second, we remove "bmi" as a predictor for all variables, to ensure that "bmi" is not used as predictor in a model together with "wgt" and "hgt". 

```{r}
pred1 <- pred
pred1["bmi", c("hgt", "wgt")] <- 0
pred1[,"bmi"] <- 0

```

Option 2:

We remove "hgt" and "wgt" as predictors for all variables, that way they won't be together in the model with "bmi" and they will not be used as predictors for imputing "bmi".

```{r}
pred2 <- pred
pred2[, c("hgt", "wgt")] <- 0
pred2[c("hgt", "wgt"), "bmi"] <- 0

```

Maybe there are other options?

These changes are needed, because bmi is calculated directly from height and weight. So using these variables together results in multi-collinearity problems with the model. 

**e. Use the adjusted predictor matrix to impute the boys dataset again, with 10 imputations and 10 iterations. Inspect the iteration plots again, do you see improvements for hgt, wgt and bmi?**


```{r}
imp1 <- mice(boys, m = 10, maxit = 10, pred = pred1)
plot(imp1)
imp2 <- mice(boys, m = 10, maxit = 10, pred = pred2)
plot(imp2)
```


**f. Another way to deal with the relation between hgt and wgt with bmi is to use "passive imputation" to impute the bmi variable. Adjust the method and predictor matrix in such a way that the bmi variable is passively imputed by hgt and wgt. Inspect the iteration plots again, do you see improvements for hgt, wgt and bmi?** 

The formula for bmi is $bmi =  \frac{weight}{height_{meters}^2}$. This formula is added as imputation method to compute missing bmi values, from the imputed weight and height values. We use the second option of the predictor matrix (option 1 is also possible), so that the updated bmi variable (from imputed hgt and wgt) is used as predictor for other variables. Option 1 might be preferred when bmi is used in the substantial analyses. 

```{r}

method <- imp$method
method["bmi"] <- "~I(wgt / (hgt/100)^2)"

imp <- mice(boys, m = 10, maxit = 10, pred = pred2, method = method)

plot(imp)
```


## Solution 7: multiple imputation iteration plots


